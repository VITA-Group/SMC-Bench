#!/bin/bash
#SBATCH --job-name=g2t_mawps_imp
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=1
#SBATCH --gpus=1
#SBATCH -t 1-00:00:00
#SBATCH --cpus-per-task=18
#SBATCH -o g2t_mawps_imp.out

source /home/sliu/miniconda3/etc/profile.d/conda.sh
source activate prune_cry

for sparsity in 0.2
do
saved_dir=/home/sliu/project_space/pruning_cfails/Math/g2t/mawps/imp/$sparsity

python -m src.main_LTH -mode train -gpu 0 -embedding roberta -emb_name roberta-base -embedding_size 768 -hidden_size 384 \
-depth 2 -lr 8e-4 -emb_lr 1e-5 -batch_size 8 -epochs 50 -dataset cv_mawps -full_cv -run_name graph2tree_run_cv_mawps_dense \
--fix --sparse_init iterative_gm --sparsity $sparsity --sparse --output_dir $saved_dir

done